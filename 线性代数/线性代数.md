# 机器学习与线性代数
- 线性代数只是一部分
- 统计学
- 凸优化
## 什么是向量？
- 两个视角看似不同,但可以相互转化
- 空间中的一个点，可以看做从原点指向这个点的一个方向
## 向量更多术语和表示法
- 行向量和列向量 (3,4)^T 表示列向量
## 向量的基本运算
### 向量的加法
(5,2)+(2,5)=(7,7)
### 向量的数量加法
2*(5,2)=(10,4)
### 零向量
u向量+o向量=u向量证明是零向量
### 向量的长度
||u向量||表示向量的模
### 单位向量
u^ = 1/u的模 * 向量u
单位向量的莫等于1
### 向量的点乘（内积）
两个向量相乘的结果是一个数（标量）
=两个向量的模相乘*cos=x1*x2+y1*y2
#### 点乘的应用
判断两个向量的相似程度（推荐系统）
∠ - 相似
∟ - 无关
钝角 - 背离
## 矩阵 Matrix
### 矩阵的基本运算
#### 相加
A+B  = 每个元素相加
#### 矩阵和向量的乘法
矩阵T实际上将向量a转化成了向量b
可以把矩阵理解成向量的函数
#### 矩阵和矩阵的乘法
1行n列 * n列1行= 1行1列
1x+4 1+2y
4x+6 4+3y
n行1列 * 1列n行 = n行n列
矩阵乘法不符合交换律
#### 矩阵的转置
(3,4)^T 行变列
#### 单位矩阵
单位矩阵 左上角到右小角都为1的为单位矩阵
#### 逆矩阵
AB=BA=I单位矩阵
A称为可逆矩阵，或者叫非奇异矩阵
不可逆的矩阵，叫做奇异矩阵
如果一个矩阵A即存在左逆矩阵B,又存在右逆矩阵C 则B=C
可逆矩阵一定是方阵
非方阵一定不可逆
#### 矩阵的逆的性质
A的专职的逆 = A的逆的转置 
#### 把矩阵看作一个空间
#### 线性系统
未知数只能一次方项
#### 高斯消元法
#### 高斯-约旦消元法
前向过程
1.选择最上的主元，化为1
2.主元下面的所有行减去主元所在行的某个倍数，使得主元下面所有元素都为0
后向过程 从下往上
1.选择最下的主元
2.主元上面的所有行减去主元所在行的某个倍数，使得主元上面所有元素都为0    
#### 齐次线性方程组
至少有一个解 就是都为0
#### 求解矩阵的逆
不可能又无数个解
可能无解 此时矩阵A没有逆矩阵
何时无解 系数矩阵化为最简形式时有0行
如果一个方阵A有右逆B 则B也是A的左逆 即B是A的逆
#### 初等矩阵
对单位矩阵进行一次初等变化得到的结果矩阵 通常记作E
#### 矩阵的逆为什么这么重要
Ax = b ; x=A^-1 b 
如果A不变的情况下，b会变化的条件下，大大加快计算速度
矩阵A可逆 -> 线性系统Ax=0只 有唯一解,x=0 -> rref(x)=单位矩阵 -> A可以表示成一系列初等矩阵的乘积 -> 矩阵A可逆 A是非奇异矩阵
->方阵A的列向量线性无关->方针A的列向量可以生成n维空间
#### 矩阵的LU分解
LU分解的计算的复杂度O(0.5n^3)
交换列需要右乘矩阵
交换行需要左乘矩阵
#### 线性组合
三维空间中的任何一个向量 都是其三个标准单位向量的一个线性组合
#### 线性相关和线性无关
##### 线性相关
对于若干个n维向量 v1,v2,v3,v4....vp 存在一组k不全为0,使得k1*v1....=0 则称v1,v2...线性相关
m个n维向量v1,v2,v3,v4 若m>n 则v1,v2,v3,v4 线性相关
#### 生成空间
#### 生成的基
若一组向量可以生成整个n维空间，且线性无关，这组向量一定有n个则称为这组向量为这个n维空间的一组基
#### 空间的基的性质
如果n维空间的p个向量 v1,v2,v3,v4,...vp 线性无关 则:p<=n
如果n维空间的p个向量 v1,v2,v3,v4,...vp 线性相关 则:p>n
如果p个向量 v1,v2,v3,...vp 可以生成n维空间 则：p>=n
如果p个向量 v1,v2,v3,...vp 可以生成n维空间的基 则：p=n
## 空间、向量空间和欧几里得空间
### 欧几里得空间
是有序实数元组的集合 二维R^2 三维R^3
### 向量空间
空间中的元素是"向量"
### 子空间
过原点的一个m维空间(m<n) 是n维空间的一个子空间
### 维度
### 正交基和标准正交基
一组向量，如果两两正交，则成为正交向量组
正交非零向量组一定线性无关
### 一维投影
### 行列式
行列式是方阵的一个属性
行列式表示向量组再空间中形成的有向体积
#### 行列式的四大基本性质
